{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74608cef",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3e86a",
   "metadata": {},
   "source": [
    "### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8278b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2cf0c",
   "metadata": {},
   "source": [
    "### Defining the Sigmoid function for activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec26f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# The learning rate, eta in the weight step equation\n",
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee2545",
   "metadata": {},
   "source": [
    "### Initialize data records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f155871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data: x, Output data: y, and Inintial weights: w\n",
    "w = np.array([0.5, -0.5, 0.3, 0.1])\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c02896",
   "metadata": {},
   "source": [
    "### The linear combination performed by the node h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b2933ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.dot(x, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0573309",
   "metadata": {},
   "source": [
    "### The neural network output ( y-hat = f(h) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2df8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_output = sigmoid(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05fdf20",
   "metadata": {},
   "source": [
    "### Calculate the error term (lowercase delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ffbf9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output error (y - y-hat)\n",
    "error = y - nn_output\n",
    "\n",
    "# output gradient (f'(h))\n",
    "output_gradient = sigmoid_prime(h)\n",
    "\n",
    "# error term \n",
    "error_term = error * output_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419e380",
   "metadata": {},
   "source": [
    "### Calculate change in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cc213c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent step \n",
    "del_w = learning_rate  *error_term*  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72f89eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network output:\n",
      "0.3775406687981454\n",
      "Amount of Error:\n",
      "0.1224593312018546\n",
      "Change in Weights:\n",
      "[0.01438919871308019, 0.02877839742616038]\n"
     ]
    }
   ],
   "source": [
    "# Optional print\n",
    "print('Neural Network output:')\n",
    "print(nn_output)\n",
    "print('Amount of Error:')\n",
    "print(error)\n",
    "print('Change in Weights:')\n",
    "print(del_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43689f73",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import features, targets, features_test, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to same seed to make debugging easier\n",
    "np.random.seed(42)\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdf5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "weights = np.random.normal(scale = 1 / n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4474e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # Loop through all records, x is the input, y is the target.\n",
    "        # Calculate the output.\n",
    "        output = sigmoid(np.dot(x, weights))\n",
    "        # Calculate the error.\n",
    "        error = y - output \n",
    "        # Calculate the error term.\n",
    "        error_term = error * sigmoid_prime(np.dot(x, weights))\n",
    "        # Calculate the change in weights for this sample and add it to the total weight change.\n",
    "        del_w += error_term * x\n",
    "        \n",
    "    # Update the weights.\n",
    "    weights += learnrate * del_w / n_records\n",
    "    \n",
    "    # Printing out the mean square error on the training set every 100 epochs.\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
